---
applyTo: "**"
description: Project context and overview
---

# Project Context
This is a Python project for scraping and generating Chuck Norris quotes. The project emphasizes code quality, testability, and best practices.

# Architecture Patterns

## Scraper Module
- Separate concerns: fetch, parse, transform, load
- Handle multiple data formats (JSON, HTML, CSV)
- Implement retry logic for network failures
- Use appropriate error handling for malformed data
- Log progress and errors appropriately

## Generator Module
- Optimize database queries for performance
- Support multiple output formats
- Implement streaming for large outputs
- Provide reproducible randomness with seeds
- Handle edge cases (empty database, invalid counts)

# CLI Parameters

## Scraper CLI Parameters
- `-s, --sources`: List of URLs or sources to scrape (space-separated)
- `-o, --output`: Output file path base (default: scraper/quotes.db)
- `-f, --format`: Output format - sqlite, csv, or both (default: both)
- `-v, --verbose`: Enable verbose logging
- `-d, --dry-run, --dryrun`: Validate sources and simulate scraping without network calls
- `-t, --threads, --thread`: Number of concurrent threads for parallel processing (default: 4)

## Generator CLI Parameters
- `-c, --count`: Number of quotes to generate (default: 1, max: 10,000,000)
- `-s, --seed`: Random seed for reproducible output (default: None for truly random)
- `-o, --output`: Output file path (default: stdout)
- `-f, --format`: Output format - text, json, or csv (default: text)
- `-d, --database`: Path to the quotes database (default: scraper/quotes.db)
- `-v, --verbose`: Enable verbose logging

## CLI Development
- Use argparse for command-line interfaces
- Provide comprehensive help text with examples
- Support both short and long option forms
- Validate parameters before processing
- Return appropriate exit codes
